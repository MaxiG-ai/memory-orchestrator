"""
Pydantic models for Open Responses API standard.

This module implements all required types from the Open Responses specification
(https://www.openresponses.org/reference) for benchmark-agnostic LLM evaluation.
"""

from enum import Enum
from typing import Any, Dict, List, Literal, Optional, Union

from pydantic import BaseModel, ConfigDict, Field


# =============================================================================
# ENUMS
# =============================================================================


class MessageRole(str, Enum):
    """Role of a message in the conversation.

    Values:
        user: End-user input in the conversation.
        assistant: Model-generated content in the conversation.
        system: System-level instructions that set global behavior.
        developer: Developer-supplied guidance that shapes the assistant's behavior.
    """

    user = "user"
    assistant = "assistant"
    system = "system"
    developer = "developer"


class ItemStatus(str, Enum):
    """Status of an item (message, function call, etc).

    Values:
        in_progress: Model is currently sampling this item.
        completed: Model has finished sampling this item.
        incomplete: Model was interrupted from sampling this item partway through.
    """

    in_progress = "in_progress"
    completed = "completed"
    incomplete = "incomplete"


class ResponseStatus(str, Enum):
    """Status of a response.

    Values:
        queued: Response is queued for processing.
        in_progress: Response is being generated.
        completed: Response generation completed successfully.
        failed: Response generation failed with an error.
        incomplete: Response generation was interrupted.
    """

    queued = "queued"
    in_progress = "in_progress"
    completed = "completed"
    failed = "failed"
    incomplete = "incomplete"


class ToolChoiceValue(str, Enum):
    """Controls whether the model should use tools.

    Values:
        none: Restrict the model from calling any tools.
        auto: Let the model choose the tools from among the provided set.
        required: Require the model to call a tool.
    """

    none = "none"
    auto = "auto"
    required = "required"


# =============================================================================
# CONTENT PARTS
# =============================================================================


class InputTextContent(BaseModel):
    """A text input to the model."""

    type: Literal["input_text"] = "input_text"
    text: str = Field(..., description="The text input to the model")


class OutputTextContent(BaseModel):
    """A text output from the model."""

    type: Literal["output_text"] = "output_text"
    text: str = Field(..., description="The text output from the model")
    annotations: List[Any] = Field(
        default_factory=list, description="The annotations of the text output"
    )
    logprobs: List[Any] = Field(
        default_factory=list, description="Log probabilities if requested"
    )


# =============================================================================
# ITEMS
# =============================================================================


class MessageItem(BaseModel):
    """A message to or from the model."""

    type: Literal["message"] = "message"
    id: Optional[str] = Field(None, description="The unique ID of the message")
    role: MessageRole = Field(..., description="The role of the message author")
    content: Union[List[Union[InputTextContent, OutputTextContent, Any]], str] = Field(
        ..., description="The message content as array of parts or string"
    )
    status: Optional[ItemStatus] = Field(None, description="The status of the message")


class FunctionCallItem(BaseModel):
    """A function tool call generated by the model."""

    type: Literal["function_call"] = "function_call"
    id: Optional[str] = Field(None, description="The unique ID of the function call")
    call_id: str = Field(
        ..., description="The unique ID of the function tool call generated"
    )
    name: str = Field(..., description="The name of the function to call")
    arguments: str = Field(..., description="The function arguments as a JSON string")
    status: ItemStatus = Field(..., description="The status of the function call")


class FunctionCallOutputItem(BaseModel):
    """A function tool call output returned by the tool."""

    type: Literal["function_call_output"] = "function_call_output"
    id: Optional[str] = Field(
        None, description="The unique ID of the function call output"
    )
    call_id: str = Field(
        ..., description="The unique ID of the function tool call generated by model"
    )
    output: Union[str, List[Any]] = Field(
        ..., description="The output of the function tool call (JSON string or list)"
    )
    status: ItemStatus = Field(..., description="The status of the item")


# Union type for all item types
Item = Union[MessageItem, FunctionCallItem, FunctionCallOutputItem]


# =============================================================================
# TOOLS
# =============================================================================


class FunctionTool(BaseModel):
    """Defines a function the model can choose to call.

    Used to provide function definitions to the model during response generation.
    """

    type: Literal["function"] = "function"
    name: str = Field(..., description="The name of the function to call")
    description: Optional[str] = Field(
        None, description="A description of the function for the model"
    )
    parameters: Optional[Dict[str, Any]] = Field(
        None, description="A JSON schema object describing the function parameters"
    )
    strict: Optional[bool] = Field(
        True, description="Whether to enforce strict parameter validation"
    )


class SpecificFunctionChoice(BaseModel):
    """Specifies a particular function the model should call."""

    type: Literal["function"] = "function"
    name: str = Field(..., description="The name of the function tool to call")


# Union type for tool choice
ToolChoice = Union[ToolChoiceValue, SpecificFunctionChoice]


# =============================================================================
# REQUEST
# =============================================================================


class OpenResponsesRequest(BaseModel):
    """Request body for the Open Responses API.

    Used to generate text, execute tools, and handle multi-turn conversations.
    Supports both synchronous requests and streaming for real-time output.
    """

    model_config = ConfigDict(populate_by_name=True)

    model: str = Field(..., description="The model to use for this request")
    input: Union[str, List[Item]] = Field(
        ...,
        description="Context to provide to the model. String or array of input items.",
    )
    tools: Optional[List[FunctionTool]] = Field(
        None, description="List of tools the model may call"
    )
    tool_choice: Optional[ToolChoice] = Field(
        None, description="Controls which tool the model should use"
    )
    temperature: Optional[float] = Field(
        None,
        description="Sampling temperature between 0 and 2. Higher = more random.",
    )
    top_p: Optional[float] = Field(
        None,
        description="Nucleus sampling parameter between 0 and 1",
    )
    max_output_tokens: Optional[int] = Field(
        None, description="Maximum number of tokens the model may generate"
    )
    max_tool_calls: Optional[int] = Field(
        None, description="Maximum number of tool calls the model may make"
    )
    parallel_tool_calls: Optional[bool] = Field(
        True, description="Whether the model may call multiple tools in parallel"
    )
    metadata: Optional[Dict[str, Any]] = Field(
        None, description="Key-value pairs for storing additional information"
    )


# =============================================================================
# RESPONSE
# =============================================================================


class InputTokensDetails(BaseModel):
    """A breakdown of input token usage."""

    cached_tokens: Optional[int] = Field(
        None, description="Number of input tokens served from cache"
    )


class OutputTokensDetails(BaseModel):
    """A breakdown of output token usage."""

    reasoning_tokens: Optional[int] = Field(
        None, description="Number of output tokens attributed to reasoning"
    )


class Usage(BaseModel):
    """Token usage statistics for the response."""

    input_tokens: int = Field(..., description="Number of input tokens used")
    output_tokens: int = Field(..., description="Number of output tokens generated")
    total_tokens: int = Field(..., description="Total number of tokens used")
    input_tokens_details: Optional[InputTokensDetails] = Field(
        None, description="Breakdown of input token usage"
    )
    output_tokens_details: Optional[OutputTokensDetails] = Field(
        None, description="Breakdown of output token usage"
    )


class DebugInfo(BaseModel):
    """Debug information about memory processing.

    Contains details about compression and memory strategy used.
    """

    memory_method: str = Field(..., description="The memory method/strategy used")
    input_token_count: int = Field(
        ..., description="Number of tokens in original input"
    )
    compressed_token_count: int = Field(
        ..., description="Number of tokens after compression"
    )
    compression_ratio: float = Field(..., description="Ratio of compression achieved")
    strategy_metadata: Dict[str, Any] = Field(
        ..., description="Additional metadata from the strategy"
    )
    processing_time_ms: float = Field(
        ..., description="Time spent processing in milliseconds"
    )
    loop_detection: bool = Field(
        ..., description="Whether loop detection was triggered"
    )
    compressed_messages: Optional[List[Any]] = Field(
        None, description="The compressed messages if available"
    )
    original_messages: Optional[List[Any]] = Field(
        None, description="The original messages if available"
    )


class OpenResponsesResponse(BaseModel):
    """Response body from the Open Responses API.

    Contains the generated output, usage statistics, and optional debug info.
    """

    model_config = ConfigDict(populate_by_name=True)

    id: str = Field(..., description="The unique ID of the response")
    object: Literal["response"] = Field(
        "response", description="The object type, always 'response'"
    )
    created_at: int = Field(
        ..., description="Unix timestamp (seconds) for when response was created"
    )
    completed_at: Optional[int] = Field(
        None, description="Unix timestamp for when response was completed"
    )
    status: ResponseStatus = Field(..., description="The status of the response")
    model: str = Field(..., description="The model that generated this response")
    output: List[Item] = Field(
        ..., description="The output items generated by the model"
    )
    usage: Optional[Usage] = Field(None, description="Token usage statistics")
    tools: Optional[List[FunctionTool]] = Field(
        None, description="Tools that were available during generation"
    )
    tool_choice: Optional[ToolChoice] = Field(
        None, description="Tool choice setting used"
    )
    temperature: Optional[float] = Field(None, description="Sampling temperature used")
    max_output_tokens: Optional[int] = Field(
        None, description="Maximum output tokens allowed"
    )
    parallel_tool_calls: Optional[bool] = Field(
        None, description="Whether parallel tool calls were allowed"
    )
    metadata: Optional[Dict[str, Any]] = Field(
        None, description="Developer-defined metadata"
    )
    error: Optional[Dict[str, Any]] = Field(
        None, description="Error info if response failed"
    )
    debug_info: Optional[DebugInfo] = Field(
        None, description="Debug information about memory processing"
    )


class ErrorResponse(BaseModel):
    """Error response from the API."""

    error: Dict[str, Any] = Field(..., description="Error details")
